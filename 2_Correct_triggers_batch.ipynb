{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the triggers\n",
    "\n",
    "This step corrects the parasite/artifact triggers and the potential delays between the trigger and the actual audio stimulus onset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate in the OS and call folders\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# Get the username automatically\n",
    "import getpass\n",
    "\n",
    "# Perform plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "# Date and time\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td\n",
    "\n",
    "# Find delay\n",
    "from find_delay import find_delay\n",
    "\n",
    "# Load Matlab file\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# MEG processing\n",
    "import mne\n",
    "from mne_bids import (\n",
    "    write_raw_bids,\n",
    "    read_raw_bids,\n",
    "    BIDSPath,\n",
    "    write_meg_calibration,\n",
    "    write_meg_crosstalk,\n",
    "    mark_channels,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "user = getpass.getuser()\n",
    "path_data = op.join('/export/home', user, 'lab/MEG_EXPERIMENTS/BLCOMP/DATA/FIF/')\n",
    "\n",
    "# Subjects (all of the subjects from the experiment)\n",
    "subjects_paths = {\"subject_01a\": 'path_to_subject_01/session_01/block_01',\n",
    "                  \"subject_01b\": 'path_to_subject_01/session_02/block_01',\n",
    "                  \"subject_02a\": 'path_to_subject_02/session_01/block_01',\n",
    "                  \"subject_02b\": 'path_to_subject_02/session_02/block_01'}\n",
    "\n",
    "subject_mat = {\"subject_01a\": \"0001.mat\",\n",
    "               \"subject_01b\": \"0002.mat\",\n",
    "               \"subject_02a\": \"0003.mat\",\n",
    "               \"subject_02b\": \"0004.mat\"}\n",
    "\n",
    "# Define the raw BIDS output path\n",
    "path_output = op.join('/export', 'home', user, 'public', 'MEGtrain')\n",
    "path_bids = op.join(path_output, 'bids')\n",
    "\n",
    "# Calibration and crosstalk files \n",
    "path_maxfilter_parameters = op.join(path_output, \"scripts\", \"maxfilter_parameters\")\n",
    "fine_cal_file = op.join(path_maxfilter_parameters, \"sss_cal_3049.dat\")\n",
    "crosstalk_file = op.join(path_maxfilter_parameters, \"ct_sparse.fif\")\n",
    "\n",
    "# Define the preprocessing output path\n",
    "path_preprocessing = op.join(path_output, \"derivatives\", \"Preprocessing\")\n",
    "\n",
    "# Define the eelbrain path\n",
    "path_eelbrain_meg = op.join(path_output, 'eelbrain', 'meg')\n",
    "os.makedirs(path_eelbrain_meg, exist_ok=True)\n",
    "\n",
    "# Define the MAT paths\n",
    "path_mat_files = op.join('/export', 'home', user, 'public', 'MEGtrain', 'Scripts', 'MEG Analysis', 'MAT')\n",
    "path_figures = op.join('/export', 'home', user, 'public', 'MEGtrain', 'Scripts', 'MEG Analysis', 'Figures')\n",
    "path_videos = op.join('/export', 'home', user, 'lab', 'path_to_original_audios_or_videos')\n",
    "\n",
    "# Empty room\n",
    "path_empty_room = op.join('/export/home', user, 'lab/MEG_EXPERIMENTS/EMPTYROOM/DATA/')\n",
    "\n",
    "class Subject(object):\n",
    "\n",
    "    def __init__(self, subject):\n",
    "        self.name = subject\n",
    "\n",
    "        if subject not in subjects_paths.keys():\n",
    "            raise Exception(\"Subject name not found.\")\n",
    "        self.fif = subjects_paths[subject] + \".fif\"\n",
    "        self.number = subject[8:10]\n",
    "        self.session = \"01\"\n",
    "        self.visit = \"\"\n",
    "        self.raw_fif_name = op.join(path_data, self.fif)\n",
    "        self.sub = \"sub-\" + self.number\n",
    "\n",
    "        self.path_derivatives = BIDSPath(subject = self.number, session = self.session, task = 'track', run = '01', suffix = \"meg\", root = path_preprocessing)\n",
    "        self.path_bids_raw = BIDSPath(subject = self.number, session = self.session, task = 'track', run = '01', suffix = \"meg\", root = path_bids)\n",
    "        self.path_bids_empty_room = BIDSPath(subject = self.number, session = self.session, task = 'emptyroom', run = '01', suffix = \"meg\", root = path_bids)\n",
    "        self.path_derivatives_er = BIDSPath(subject = self.number, session = self.session, task = 'emptyroom', run = '01', suffix = \"meg\", root = path_preprocessing)\n",
    "\n",
    "        self.path_downsampled_sss = op.join(self.path_derivatives.directory, self.path_derivatives.basename.replace(\"meg\", \"sss\") + \".fif\")\n",
    "        self.path_ica_solution = op.join(self.path_derivatives.directory, self.path_derivatives.basename.replace(\"meg\", \"ica_solution\") + \".fif\")\n",
    "        self.path_ica = op.join(self.path_derivatives.directory, self.path_derivatives.basename.replace(\"meg\", \"ica\") + \".fif\")\n",
    "        self.path_eelbrain = op.join(path_eelbrain_meg, self.sub, self.sub + \"_track\" + self.visit + \"-raw.fif\")\n",
    "        self.path_downsampled_sss_er = op.join(self.path_derivatives_er.directory, self.path_derivatives_er.basename.replace(\"meg\", \"sss\") + \".fif\")\n",
    "        self.path_eelbrain_er = op.join(path_eelbrain_meg, self.sub, self.sub + \"_emptyroom\" + self.visit + \"-raw.fif\")\n",
    "\n",
    "        self.path_mat = op.join(path_mat_files, subject_mat[self.name])\n",
    "\n",
    "        os.makedirs(op.join(path_eelbrain_meg, self.sub), exist_ok=True)\n",
    "\n",
    "    def print_name(self):\n",
    "        s = \"#\"\n",
    "        print(\"\")\n",
    "        print(s * (len(self.name) + 10))\n",
    "        print(s + s + \"   \" + self.name.upper() + \"   \" + s + s)\n",
    "        print(s * (len(self.name) + 10))\n",
    "        print(\"\")\n",
    "\n",
    "all_subjects = {}\n",
    "for subject_name in subjects_paths.keys():\n",
    "    all_subjects[subject_name] = Subject(subject_name)\n",
    "\n",
    "subjects = []\n",
    "for subject_name in all_subjects.keys():\n",
    "    subjects.append(all_subjects[subject_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct the events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the events\n",
    "Determine which triggers are to remove/correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 27\n",
    "subject = subjects[sub-1]\n",
    "print(subject.name)\n",
    "\n",
    "path_data = op.join(subject.path_derivatives.directory, subject.path_derivatives.basename.replace(\"meg\", \"ica\") + \".fif\")\n",
    "data = mne.io.read_raw_fif(path_data, preload = False)\n",
    "\n",
    "events = mne.find_events(data, stim_channel = \"STI101\", shortest_event = 1)\n",
    "\n",
    "plot = mne.viz.plot_events(events, data.info[\"sfreq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove specific triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IDs of the subjects you want to preprocess\n",
    "selected_subjects = [\"subject_01a\", \"subject_01b\", \"subject_02a\", \"subject_02b\"]\n",
    "\n",
    "# The triggers ID you want removed (e.g [4, 20]). All triggers with these values will be removed.\n",
    "events_to_remove_all = {\"subject_01a\": [],\n",
    "                        \"subject_01b\": [],\n",
    "                        \"subject_02a\": [],\n",
    "                        \"subject_02b\": []}\n",
    "\n",
    "# Some trigger occurrences you want removed (e.g., the 8th and 11th occurrence of the trigger 32 will be {32: [8, 11]}).\n",
    "# Beware, indices start at 1! Meaning, the first occurrence of a trigger will be 1.\n",
    "unwanted_occurrences_all = {\"subject_01a\": {},    \n",
    "                            \"subject_01b\": {},\n",
    "                            \"subject_02a\": {},\n",
    "                            \"subject_02b\": {}}\n",
    "\n",
    "# Set the max trigger value (all triggers over this value will be removed).\n",
    "max_trigger_value = 105\n",
    "\n",
    "# Conditions to triggers\n",
    "conditions_to_triggers = {\"AO_U_XX\": 10, \"AO_M_XX\": 11,\n",
    "                          \"VO_U_BD\": 20, \"VO_M_BD\": 21, \"VO_X_SK\": 22, \"VO_X_SC\": 23,\n",
    "                          \"AV_U_BD\": 30, \"AV_M_BD\": 31, \"AV_X_SK\": 32, \"AV_X_SC\": 33}\n",
    "\n",
    "# Set to True if you want to set the middle value for each of the events to zero\n",
    "# (each event is saved as an array of three values: the timestamp, the channel value before the trigger, and the trigger value).\n",
    "# (to have a cleaner list, set the second value to 0).\n",
    "set_middle_value_at_0 = True\n",
    "\n",
    "# Save the outlier delays to show them at the end\n",
    "outlier_threshold = (200, 230)  # We set our outlier delay below 200 and over 230\n",
    "outliers = {}\n",
    "\n",
    "for selected_subject in selected_subjects:\n",
    "\n",
    "    # Load the necessary data\n",
    "    subject = all_subjects[selected_subject]\n",
    "    print(subject.name)\n",
    "\n",
    "    path_data_resampled = op.join(subject.path_derivatives.directory, subject.path_derivatives.basename.replace(\"meg\", \"ica\") + \".fif\")\n",
    "    data_resampled = mne.io.read_raw_fif(path_data_resampled, preload = True, verbose = False)\n",
    "    data_original = mne.io.read_raw_fif(subject.path_bids_raw, preload = True, verbose = False)\n",
    "\n",
    "    # Load the events\n",
    "    events = mne.find_events(data_resampled, stim_channel = \"STI101\", shortest_event = 1, verbose = False)\n",
    "    \n",
    "    # PART ONE: we correct the trigger values\n",
    "\n",
    "    # 1A. We delete the unwanted trigger values\n",
    "    events_to_remove = events_to_remove_all[subject.name]\n",
    "    events_filtered_1 = []\n",
    "\n",
    "    for event in events:\n",
    "        if event[2] not in events_to_remove:\n",
    "            #event[1] = 0\n",
    "            events_filtered_1.append(event)\n",
    "\n",
    "    # 1B. We delete the unwanted occurrences of some events\n",
    "    unwanted_occurrences = unwanted_occurrences_all[subject.name]\n",
    "    events_count = {}\n",
    "    events_filtered_2 = []\n",
    "\n",
    "    for event in events_filtered_1:\n",
    "        events_count[event[2]] = events_count.get(event[2], 0) + 1\n",
    "\n",
    "        if not(event[2] in unwanted_occurrences.keys() and events_count[event[2]] in unwanted_occurrences[event[2]]):\n",
    "            events_filtered_2.append(event)\n",
    "\n",
    "    # 1C. We set the proper 99 events (in the case where they are noisy)\n",
    "    # (in this experiment, 99 meant the end of a video, and would always be succeeded by a button press,\n",
    "    # which was a number between 101 and 104. Comment these lines if not applicable for your experiment).\n",
    "    for i in range(len(events_filtered_2)):\n",
    "        if i != 0 and events_filtered_2[i][2] in [101, 102, 103, 104] and events_filtered_2[i-1][2] != 99:\n",
    "            events_filtered_2[i-1][2] = 99    \n",
    "    \n",
    "    # 1D. We remove any event value over max_trigger_value\n",
    "    events_filtered_3 = []\n",
    "    for event in events_filtered_2:\n",
    "        if event[2] < max_trigger_value:\n",
    "            events_filtered_3.append(event)\n",
    "\n",
    "    if set_middle_value_at_0:\n",
    "        for event in events_filtered_3:\n",
    "            event[1] = 0\n",
    "\n",
    "    print(f\"Number of events before: {len(events)}, Number of events after: {len(events_filtered_3)}\")\n",
    "    sorted_events = list(set([event[2] for event in events_filtered_3]))\n",
    "    sorted_events.sort()\n",
    "    print(f\"Unique events: {sorted_events}\")\n",
    "    print(f\"Number of events with a value at index 1 different from zero: {len(events_filtered_3)-[event[1] for event in events_filtered_3].count(0)}\\n\")\n",
    "\n",
    "    for event in events_filtered_3:\n",
    "        print(event)\n",
    "\n",
    "    # PART TWO: We correct the trigger delays\n",
    "\n",
    "    # 2A. We get the sampling of the original and resampled data\n",
    "    meg_freq_original = data_original.info[\"sfreq\"]\n",
    "    meg_freq_resampled = data_resampled.info[\"sfreq\"]\n",
    "    ratio_freq = meg_freq_original / meg_freq_resampled\n",
    "\n",
    "    # 2B. Get the timestamps of the triggers of interest\n",
    "    events = events_filtered_3\n",
    "    onsets = np.array([event for event in events if event[2] in [10, 11, 20, 21, 22, 23, 30, 31, 32, 33]])  # Beginnings of the videos\n",
    "    offsets = np.array([event for event in events if event[2] == 99])  # Ends of the videos\n",
    "    max_duration = np.max(offsets[:, 0] - onsets[:, 0])  # Max duration of a video\n",
    "\n",
    "    # 2C. We multiply the onsets and offsets by the ratio freq\n",
    "    for i in range(len(onsets)):\n",
    "        onsets[i][0] *= ratio_freq\n",
    "        offsets[i][0] *= ratio_freq\n",
    "    max_duration *= ratio_freq\n",
    "\n",
    "    # 2D. We create the epochs\n",
    "    audio_epochs = []\n",
    "    for onset, offset in zip(onsets, offsets):\n",
    "        abs_onset = onset[0] - data_original.first_samp\n",
    "        abs_offset = offset[0] - data_original.first_samp\n",
    "        epoch = data_original.pick([\"MISC001\", \"STI101\"])[:, abs_onset:abs_offset][0]\n",
    "        audio_epochs.append(epoch[0])\n",
    "\n",
    "    \n",
    "    print(f\"Number of epochs created: {len(audio_epochs)}.\")\n",
    "    print(f\"Max event duration: {max_duration} ms.\")\n",
    "    \n",
    "    # 2E. Load the data from the MAT files and get the video file name for each trial\n",
    "    mat_contents = loadmat(subject.path_mat)\n",
    "    mat_videos = mat_contents[\"data\"][0][0][3][0]\n",
    "\n",
    "    # 2F. We turn this into a list we can go through\n",
    "    videos = []\n",
    "    for i in range(len(mat_videos)):\n",
    "        videos.append(mat_videos[i][0][0][0])\n",
    "\n",
    "    # The two first videos of subject 10 are missing\n",
    "    if subject.name == \"subject_10\":\n",
    "        videos = videos[2:]\n",
    "\n",
    "    print(f\"Number of events recorded in the MAT file: {len(videos)}.\")\n",
    "\n",
    "    # 2G. Looping through all the events\n",
    "    trial = 0\n",
    "    delays = {}\n",
    "    corrs = {}\n",
    "\n",
    "    os.makedirs(op.join(path_figures, subject.name))\n",
    "\n",
    "    for epoch in audio_epochs:\n",
    "        print(f\"Trial {trial + 1} of {len(audio_epochs)}\")\n",
    "        \n",
    "        trigger = onsets[trial][2]\n",
    "        onset = onsets[trial][0]/meg_freq_original\n",
    "        offset = offsets[trial][0]/meg_freq_original\n",
    "        print(f\"\\tTrigger {trigger}: onset {onset}, offset {offset}, duration {offset-onset}\")\n",
    "\n",
    "        if trigger in [20, 21, 22, 23]:\n",
    "            delays[trial] = np.nan\n",
    "            print(f\"\\tSilent trial: no delay calculation possible. Moving to the next trial...\")\n",
    "\n",
    "        else:\n",
    "            # We load the video, and extract the audio\n",
    "            video = videos[trial]\n",
    "            path_video = op.join(path_videos, video[:7], video)\n",
    "            mp4_video = VideoFileClip(path_video)\n",
    "            mp4_audio = mp4_video.audio\n",
    "            audio_sound_array = np.array(list(mp4_audio.iter_frames()))[:, 0]\n",
    "            print(f\"\\tVideo {video}, duration {mp4_video.duration}\")\n",
    "            print(f\"\\tExpected trigger: {conditions_to_triggers[video[:7]]}\")\n",
    "            print(f\"\\tDuration difference: {np.round(np.abs(mp4_video.duration - (offset - onset)), 3)} ms\")\n",
    "\n",
    "            if conditions_to_triggers[video[:7]] != trigger:\n",
    "                raise Exception(f\"The trigger value ({trigger}) does not match what the expected trigger should be ({conditions_to_triggers[video[:7]]}).\")\n",
    "\n",
    "            delay, corr = find_delay(array_1 = epoch, \n",
    "                                     array_2 = audio_sound_array, \n",
    "                                     freq_array_1 = meg_freq_original, \n",
    "                                     freq_array_2 = mp4_audio.fps,\n",
    "                                     resampling_rate = 1000,\n",
    "                                     return_delay_format = \"ms\", \n",
    "                                     threshold = 0.1, \n",
    "                                     plot_figure = False,\n",
    "                                     plot_intermediate_steps = False,\n",
    "                                     return_correlation_value = True,\n",
    "                                     path_figure = op.join(path_figures, subject.name, str(trial+1) + \".png\"),\n",
    "                                     verbosity = 0)\n",
    "            print(f\"\\tDelay: {delay} ms; correlation: {np.round(corr*100, 2)}%.\")\n",
    "            delays[trial] = delay\n",
    "            corrs[trial] = corr\n",
    "\n",
    "        trial += 1\n",
    "\n",
    "    # 2H. Calculating the average delay and attributing it to the silent trials\n",
    "    average_delay = np.round(np.nanmean(list(delays.values())))\n",
    "    for trial in delays.keys():\n",
    "        if np.isnan(delays[trial]):\n",
    "            delays[trial] = np.round(average_delay)\n",
    "            corrs[trial] = \"N/A\"\n",
    "\n",
    "        if not outlier_threshold[0] < delays[trial] < outlier_threshold[1]:\n",
    "            if subject.name in outliers.keys():\n",
    "                outliers[subject.name].append({\"trial\": trial, \"video\": videos[trial], \"delay\": delays[trial], \"corr\": corrs[trial]})\n",
    "            else:\n",
    "                outliers[subject.name] = [{\"trial\": trial, \"video\": videos[trial], \"delay\": delays[trial], \"corr\": corrs[trial]}]\n",
    "\n",
    "    print(f\"Average delay: {average_delay}.\")\n",
    "\n",
    "    # 2I. Correcting the events\n",
    "    trial = 0\n",
    "    for video in videos:\n",
    "\n",
    "        trigger = onsets[trial][2]\n",
    "        if conditions_to_triggers[video[:7]] != trigger:\n",
    "            raise Exception(f\"The trigger value ({trigger}) does not match what the expected trigger should be ({conditions_to_triggers[video[:7]]}).\")\n",
    "        \n",
    "        event_ms = np.round(events[trial][0] / meg_freq_resampled * 1000)\n",
    "        print(f\"Trial {trial+1} ({video}, {trigger}): trigger moved from {event_ms} to {event_ms + delays[trial]} (+{delays[trial]})\")\n",
    "\n",
    "        delay_freq_resampled = delays[trial] / 1000 * meg_freq_resampled\n",
    "\n",
    "        events[i][0] += np.round(delay_freq_resampled)\n",
    "\n",
    "        trial += 1\n",
    "\n",
    "    # 2J. Save the data\n",
    "    # path_data_corrected = op.join(subject.path_derivatives.directory, subject.path_derivatives.basename.replace(\"meg\", \"ec\") + \".fif\")\n",
    "    path_data_corrected = subject.path_eelbrain\n",
    "    data_resampled.add_events(np.array(events), stim_channel=\"STI101\", replace=True)\n",
    "    data_resampled.save(path_data_corrected, overwrite=True, verbose=False)\n",
    "\n",
    "    # PART THREE: We create the variable-duration events\n",
    "    # onsets = np.array([event for event in events if event[2] in [10, 11, 20, 21, 22, 23, 30, 31, 32, 33]])  # Beginnings of the videos\n",
    "    # offsets = np.array([event for event in events if event[2] == 99])  # Ends of the videos\n",
    "    # epochs = []\n",
    "\n",
    "    # if len(onsets) != len(offsets):\n",
    "    #     raise Exception(f\"There are not as many onsets {len(onsets)} as there are offsets {len(offsets)}. Impossible to create the vairable duration events.\")\n",
    "\n",
    "    # pre_stim = 200\n",
    "    # post_stim = 200\n",
    "\n",
    "    # for onset, offset in zip(onsets, offsets):\n",
    "    #     index = data.time_as_index([onset[0]/meg_freq_resampled - pre_stim, offset[0]/meg_freq_resampled + post_stim])\n",
    "    #     epoch, times = data_resampled[:, index[0]:index[1]]\n",
    "    #     epochs.append(mne.EpochsArray(np.expand_dims(epoch, 0), data_resampled.info, tmin=-pre_stim, verbose=False))\n",
    "\n",
    "    # print(f\"Epoching done. {len(epochs)} epochs found.\")\n",
    "\n",
    "    del data_original\n",
    "    del data_resampled\n",
    "\n",
    "for subject_name in outliers:\n",
    "    print(f\"Subject: {subject_name}\")\n",
    "    for trial in outliers[subject_name]:\n",
    "        print(f\"\\t{trial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the correction\n",
    "\n",
    "### Observe the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 24\n",
    "subject = subjects[sub-1]\n",
    "print(subject.name)\n",
    "\n",
    "path_data = op.join(subject.path_derivatives.directory, subject.path_derivatives.basename.replace(\"meg\", \"ec\") + \".fif\")\n",
    "data = mne.io.read_raw_fif(path_data, preload = False)\n",
    "\n",
    "events = mne.find_events(data, stim_channel = \"STI101\", shortest_event = 1)\n",
    "\n",
    "plot = mne.viz.plot_events(events, data.info[\"sfreq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in events:\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodylingual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
